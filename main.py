from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

from bs4 import BeautifulSoup
import sqlite3
import time
import re
from urllib.parse import urljoin

from message import initialize_message_table, scrape_messages

DB_PATH = "lstep_users.db"
BASE_URL = "https://step.lme.jp/"  # href ãŒç›¸å¯¾ãƒ‘ã‚¹ã§ã‚‚ OK ã«ã™ã‚‹
DT_RE = re.compile(r"(\d{4}[./-]\d{2}[./-]\d{2})\s+(\d{2}:\d{2})(?::\d{2})?")
# -------------------------
# DBåˆæœŸåŒ–ï¼ˆæ–°è¦ä½œæˆ + æ—¢å­˜DBã®ã‚«ãƒ©ãƒ è¿½åŠ ã«ã‚‚å¯¾å¿œï¼‰
# -------------------------
def ensure_users_columns(conn):
    cur = conn.cursor()
    cur.execute("PRAGMA table_info(users)")
    cols = {row[1] for row in cur.fetchall()}

    if "friend_registered_at" not in cols:
        cur.execute("ALTER TABLE users ADD COLUMN friend_registered_at TEXT")
        conn.commit()

    if "support" not in cols:
        cur.execute("ALTER TABLE users ADD COLUMN support TEXT")
        conn.commit()

    if "tags" not in cols:
        cur.execute("ALTER TABLE users ADD COLUMN tags TEXT")
        conn.commit()

def initialize_db():
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS users (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            line_name TEXT,
            href TEXT,
            support TEXT,
            friend_registered_at TEXT,
            tags TEXT
        )
    """)
    conn.commit()
    ensure_users_columns(conn)
    conn.close()

def clear_tables():
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    cursor.execute("DELETE FROM users")
    cursor.execute("DELETE FROM messages")
    conn.commit()
    conn.close()

def save_to_db(name, href, friend_registered_at=None, support=None):
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    cursor.execute(
        "INSERT INTO users (line_name, href, friend_registered_at, support) VALUES (?, ?, ?, ?)",
        (name, href, friend_registered_at, support)
    )
    conn.commit()
    conn.close()

# -------------------------
# è©³ç´°ãƒšãƒ¼ã‚¸(hrefå…ˆ)ã‹ã‚‰ã€Œå‹ã ã¡è¿½åŠ æ—¥ä»˜ã€ã‚’å–å¾—ï¼ˆæ™‚åˆ»è¾¼ã¿ï¼‰
# æ·»ä»˜ç”»åƒã®: table.tbl_info_df ã®ã€Œå‹ã ã¡è¿½åŠ æ—¥ä»˜ã€tdã®éš£ã®td
# -------------------------
DT_RE = re.compile(r"(\d{4}[./-]\d{2}[./-]\d{2})\s+(\d{2}:\d{2})")

def fetch_friend_registered_at_from_detail(driver, href, timeout=12, debug=False):
    detail_url = urljoin(BASE_URL, href)
    original_handle = driver.current_window_handle
    before_handles = set(driver.window_handles)

    driver.execute_script("window.open(arguments[0], '_blank');", detail_url)

    WebDriverWait(driver, timeout).until(
        lambda d: len(set(d.window_handles) - before_handles) == 1
    )
    new_handle = list(set(driver.window_handles) - before_handles)[0]
    driver.switch_to.window(new_handle)

    try:
        WebDriverWait(driver, timeout).until(
            EC.presence_of_element_located((By.CSS_SELECTOR, "table.tbl_info_df"))
        )

        raw = None

        # âœ… ãƒ©ãƒ™ãƒ«æºã‚Œå¸åï¼šå‹ã ã¡è¿½åŠ ã€Œæ—¥ä»˜/æ—¥æ™‚ã€ã©ã¡ã‚‰ã‚‚OK
        els = driver.find_elements(
            By.XPATH,
            "//table[contains(@class,'tbl_info_df')]"
            "//td[contains(normalize-space(.),'å‹ã ã¡è¿½åŠ ')]/following-sibling::td[1]"
        )
        if els:
            raw = els[0].text.strip()
        else:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆå¿µã®ãŸã‚ï¼‰
            soup = BeautifulSoup(driver.page_source, "html.parser")
            table = soup.select_one("table.tbl_info_df")
            if table:
                td = table.find("td", string=lambda s: s and "å‹ã ã¡è¿½åŠ " in s)
                if td and td.find_next_sibling("td"):
                    raw = td.find_next_sibling("td").get_text(" ", strip=True)

        if debug and not raw:
            print("[DEBUG] label td not found url=", driver.current_url)

        if not raw:
            return None

        m = DT_RE.search(raw)
        if not m:
            if debug:
                print("[DEBUG] datetime not matched url=", driver.current_url)
                print("[DEBUG] raw=", raw)
            return None

        date_part = m.group(1).replace(".", "-").replace("/", "-")
        time_part = m.group(2)
        return f"{date_part} {time_part}"

    finally:
        driver.close()
        driver.switch_to.window(original_handle)

# -------------------------
# ä¸€è¦§ãƒšãƒ¼ã‚¸ã‹ã‚‰ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨hrefã‚’å–ã‚Šã€è©³ç´°ãƒšãƒ¼ã‚¸ã‹ã‚‰æ—¥ä»˜ã‚’å–ã£ã¦ä¿å­˜
# -------------------------
def scrape_current_page(driver):
    html = driver.page_source
    soup = BeautifulSoup(html, "html.parser")

    rows = soup.select("table tr")
    for row in rows:
        name_tag = row.select_one("a[href*='/basic/friendlist/my_page/']")
        if not name_tag:
            continue

        href = name_tag.get("href", "")
        name = name_tag.get_text(strip=True)

        # â˜… ã“ã“ã§è©³ç´°ãƒšãƒ¼ã‚¸ã¸å–ã‚Šã«è¡Œãï¼ˆæ™‚åˆ»è¾¼ã¿ï¼‰
        friend_registered_at = None
        if href:
            friend_registered_at = fetch_friend_registered_at_from_detail(driver, href)

        print(f"{name}: {href} / friend_registered_at={friend_registered_at}")
        save_to_db(name, href, friend_registered_at=friend_registered_at)

        # é–‹ãã¾ãã‚‹ã®ã§è»½ãé–“éš”ï¼ˆå¿…è¦ãªã‚‰èª¿æ•´ï¼‰
        time.sleep(0.2)

def has_next_page(driver):
    try:
        next_button = driver.find_element(By.CSS_SELECTOR, ".glyphicon.glyphicon-menu-right")
        parent_li = next_button.find_element(By.XPATH, "./ancestor::li")
        class_attr = parent_li.get_attribute("class")
        return "disabled" not in class_attr
    except:
        return False

def go_to_next_page(driver):
    next_button = driver.find_element(By.CSS_SELECTOR, ".glyphicon.glyphicon-menu-right")
    next_button.click()
    time.sleep(2)

def scrape_user_list(driver):
    initialize_db()
    while True:
        scrape_current_page(driver)
        if has_next_page(driver):
            go_to_next_page(driver)
        else:
            break
    print("âœ… å…¨ãƒšãƒ¼ã‚¸ã®ãƒ‡ãƒ¼ã‚¿å–å¾—ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")

# ãƒ¡ã‚¤ãƒ³å‡¦ç†
if __name__ == "__main__":
    options = Options()
    options.add_experimental_option("detach", True)
    driver = webdriver.Chrome(options=options)

    driver.get("https://step.lme.jp/")
    input("ãƒ­ã‚°ã‚¤ãƒ³ãŒå®Œäº†ã—ãŸã‚‰ Enter ã‚’æŠ¼ã—ã¦ãã ã•ã„ â†’ ")

    print("ğŸŸ¡ æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªã‚¢ä¸­...")
    clear_tables()

    print("ğŸŸ¡ ä¸€è¦§ã‚’å–å¾—ä¸­...")
    scrape_user_list(driver)

    print("ğŸŸ¡ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’åˆæœŸåŒ–ä¸­...")
    initialize_message_table()

    print("ğŸŸ¡ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å–å¾—ä¸­...")
    scrape_messages(driver)

    print("ğŸ‰ å…¨å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
    driver.quit()
